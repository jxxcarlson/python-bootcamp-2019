{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "\n",
    "# This a famous data set analyzed by a famous statistician, Sir Robert Fisher\n",
    "# Data: 150 measurements of the flowers of three different species of Iris:\n",
    "# sepal length, sepal width, petal length, petal width.  Thus a 150x4 dimensional\n",
    "# data set.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "# load dataset into Pandas DataFrame\n",
    "df = pd.read_csv(url, names=['sepal length','sepal width','petal length','petal width','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_lengths = df.loc[:,'sepal length']\n",
    "sepal_lengths.shape, sepal_lengths[:5], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sepal_lengths), np.std(sepal_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_sepal_lengths = (sepal_lengths - np.mean(sepal_lengths))/np.std(sepal_lengths)\n",
    "normalized_sepal_lengths.shape, normalized_sepal_lengths[:5], normalized_sepal_lengths[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns of the data must be scaled to have\n",
    "# maan 0 and variance 1.\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "# Separating out the features\n",
    "x_unscaled = df.loc[:, features].values\n",
    "\n",
    "# Separating out the target\n",
    "y = df.loc[:,['target']].values\n",
    "\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the shapes\n",
    "\n",
    "x.shape, x_unscaled.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does it check out?\n",
    "\n",
    "print(x[0:4, 0]), print(\"----\"), print(normalized_sepal_lengths[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do PCA, projecting the data onto \n",
    "# the first two principal components\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again let's \"look into\" the data we are making:\n",
    "\n",
    "principalComponents.shape, principalComponents[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need labeals for the data:\n",
    "finalDf = pd.concat([principalDf, df[['target']]], axis = 1)\n",
    "finalDf[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we can visualize the projected data\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['target'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if we can classify the first data element by hand\n",
    "\n",
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we need its normalized form:\n",
    "\n",
    "v = x[0]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the fun part: here is the projection matrix:\n",
    "\n",
    "P = pca.components_\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And there is the projection of the firat data row:\n",
    "# Is it in the right place ont the graph?\n",
    "\n",
    "np.dot(P,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to classify an unknown flower!\n",
    "# We will need a function which takes a vector of\n",
    "# features as input and which yields the normalized\n",
    "# vector of features as output.\n",
    "\n",
    "# So we need the means and standard deviations of the columns.\n",
    "xu = x_unscaled\n",
    "xu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(xu, axis=0)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevs = np.std(xu, axis=0)\n",
    "stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = np.array([5.0, 3.4, 1.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(f):\n",
    "    return (f - means)/stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_flower = normalize(flower)\n",
    "normalized_flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2(f):\n",
    "    return np.dot(P, normalize(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify2(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(f):\n",
    "    return np.dot(P, normalize(f))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's grow or shrink the flower and then try to classify it:\n",
    "\n",
    "flower2 = np.array([5.0, 3.4, 1.3, 0.2])/0.8\n",
    "classify(flower2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: devise a way to take a flower meaurement as input and produce\n",
    "# one of the following strings as output:\n",
    "# iris-setosa, iris-versicolor, iris-virginica, unclassified\n",
    "#\n",
    "# Problem 2: add to the above: a numerical measure of confidence in\n",
    "# the classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
